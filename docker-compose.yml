version: "3"

services:
  # Database PostgreSQL
  postgres:
    container_name: reg_dub_union_postgres
    image: postgres:17
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}

      PROJECT_DB_USER: ${PROJECT_DB_USER}
      PROJECT_DB_PASSWORD: ${PROJECT_DB_PASSWORD}
      PROJECT_DB_NAME: ${PROJECT_DB_NAME}
    volumes:
      - reg_dub_union_data:/var/lib/postgresql/data
      - ./init_db:/docker-entrypoint-initdb.d
    ports:
      - "5433:5432"
    networks:
      - reg_dub_union_network

  # Backend Flask
  backend:
    container_name: reg_dub_union_backend
    build:
      context: ./website/backend
      dockerfile: Dockerfile
    environment:
      FLASK_ENV: ${FLASK_ENV}
      SQLALCHEMY_DATABASE_URI: postgresql+psycopg2://${PROJECT_DB_USER}:${PROJECT_DB_PASSWORD}@postgres:5432/${PROJECT_DB_NAME}
    depends_on:
      - postgres
    ports:
      - "5001:5001"
    volumes:
      - ./website/backend:/app
    networks:
      - reg_dub_union_network

  # Frontend Vite/ReactJS
  frontend:
    container_name: reg_dub_union_frontend
    build:
      context: ./website/frontend
      dockerfile: Dockerfile
    ports:
      - "5173:80"
    depends_on:
      - backend
    volumes:
      - ./website/frontend:/app
    networks:
      - reg_dub_union_network

  # Airflow
  airflow-scheduler:
    container_name: reg_dub_union_airflow_scheduler
    image: apache/airflow:2.10.5
    build:
      context: ./airflow
      dockerfile: Dockerfile
    environment:
      # Env Default
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"

      # Custom Env
      GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/gcp/gcp_sa_key.json
      AIRFLOW_CONN_REG_DUB_UNION_CONN: postgresql://${PROJECT_DB_USER}:${PROJECT_DB_PASSWORD}@postgres:5432/${PROJECT_DB_NAME}
      AIRFLOW_CONN_GCP_STORAGE_CONN: google-cloud-platform://?keyfile_path=/opt/airflow/gcp/gcp_sa_key.json&project_id=${GCP_PROJECT_ID}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8974/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3
    depends_on:
      - postgres
    env_file:
      - .env
    networks:
      - reg_dub_union_network
    command: "scheduler"

  airflow-webserver:
    container_name: reg_dub_union_airflow_webserver
    image: apache/airflow:2.10.5
    build:
      context: ./airflow
      dockerfile: Dockerfile
    environment:
      # Env Default
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"

      # Custom Env
      GOOGLE_APPLICATION_CREDENTIALS: /opt/airflow/gcp/gcp_sa_key.json
      AIRFLOW_VAR_BUCKET_NAME: ${AIRFLOW_VAR_BUCKET_NAME}
      AIRFLOW_VAR_CONN_ID: ${AIRFLOW_VAR_CONN_ID}
      AIRFLOW_CONN_REG_DUB_UNION_CONN: postgresql://${PROJECT_DB_USER}:${PROJECT_DB_PASSWORD}@postgres:5432/${PROJECT_DB_NAME}
      AIRFLOW_CONN_GCP_STORAGE_CONN: google-cloud-platform://?keyfile_path=/opt/airflow/gcp/gcp_sa_key.json&project_id=${GCP_PROJECT_ID}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 3
    ports:
      - "8080:8080"
    env_file:
      - .env
    depends_on:
      - postgres
    networks:
      - reg_dub_union_network
    command: "webserver --host=0.0.0.0"

volumes:
  reg_dub_union_data:

networks:
  reg_dub_union_network:
    driver: bridge
